

[embed_token]
backend = "S[EmbeddingTensor(exported_params/embed_tokens.pt),AppendIndexSelectTensor(-1),StreamGuard,SetTensorRequestSize]"
# Add(jump:batchless_prefill)
# ,Send2Queue(batchless_prefill,keep_result=1) SetTensorMsg UpdateTensorMsg
next = "contiguous_batching"

[contiguous_batching]
# init = "List[Register(cb)[ContiguousBatching(queue)], Register[S[CBTensorStatus,Forward[cb]]]]"
init = "Register[IoC[ContiguousBatching(target=node.batchable);Loop(src_queue,target=ContiguousBatching)]]"
# req CBStatus Loop(src_queue,target="") TASK_MSG_KEY xieyi / pool
# 

[batchable]
backend = 'S[TensorrtTensor,StreamGuard]'
max = 5
model = 'exported_params/batchable.onnx'
# 'model::cache' = 'export_params/batchable.trt'
# the tensorrt plugin 
#
