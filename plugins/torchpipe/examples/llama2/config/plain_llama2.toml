

[embed_token]
backend = "S[EmbeddingTensor(exported_params/embed_tokens.pt),AppendIndexSelectTensor(-1),StreamGuard,SetRequestSizeTensor,Send2Queue(batchless_prefill,keep_result=1)]"
# Add(jump:batchless_prefill)

next = "batchable"

[batchable]
backend = 'S[TensorrtTensor,StreamGuard]'
max = 5
model = 'exported_params/batchable.onnx'
# 'model::cache' = 'export_params/batchable.trt'
# the tensorrt plugin 
#
