batching_timeout = 10 #默认的凑batch的超时时间
precision = "fp16" 
instance_num=3
device_id=0
#### main graph ####
[jpg_decoder]
backend = "Torch[S[DecodeTensor,(result2other)cvtColorTensor,ResizePadTensor]]"
color = "bgr"
instance_num = 20
max_h = 416
max_w = 416

next = "detect"

[detect]
backend = "Torch[S[TensorrtTensor, PostProcYolox]]" 
batching_timeout = 10
instance_num = 2
max = 16
net_h=416
net_w=416 # for PostProcYolox
model = "../../../examples/yolox/yolox_tiny.onnx" 
"model::cache" = "./yolox_tiny.trt" 
# postprocessor = "BatchingPostProcYolox_45_30" 
next = "sub_graph"

[sub_graph] 
map="jpg_decoder[other:data,color:color],detect[TASK_BOX_KEY:TASK_BOX_KEY]"

backend = "MapReduce"
jump="cls_preprocess"

split="TASK_BOX_KEY"
# merge="score_1,score_2,result,cls_1_result"

next="final"
instance_num=40

[final]



#### sub graph ####
[cls_preprocess]
backend="Torch[S[CropTensor,ResizeTensor,cvtColorTensor]]"
resize_h=224
resize_w=224
color="rgb"
instance_num=16
# save_dir="./"

next="cls_1"

#### branch 1 ####
[cls_1]
mean = "123.675, 116.28, 103.53" # 255*"0.485, 0.456, 0.406"
std = "58.395, 57.120, 57.375" # 255*"0.229, 0.224, 0.225"
backend="Torch[S[TensorrtTensor,SoftmaxArgMaxTensor]]"
max="32;16"
model="./resnet18.onnx"
"model::cache"="./resnet18_2device.trt"

# postprocessor="SoftmaxArgMax"

next="post_cls_1"

[post_cls_1]
filter="filter_score"

mean = "123.675, 116.28, 103.53" # 255*"0.485, 0.456, 0.406"
std = "58.395, 57.120, 57.375" # 255*"0.229, 0.224, 0.225"
backend="Torch[S[TensorrtTensor,SoftmaxArgMaxTensor]]"
max="32;16"
model="././resnet50.onnx"
"model::cache"="./resnet50_2device.trt"

# postprocessor="SoftmaxArgMax"

 

#### branch 2 ####
 