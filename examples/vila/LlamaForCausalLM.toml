"Interpreter::backend" = "Ring"

'precision' = 'fp16'

# [multimodal]
# backend = 'SyncTensor[MultiModalEmbedsTensor]'
# input_embeds = '../cur_input_embeds_no_im.pt'
# next = 'llm'

# [llm]
# 'backend' = 'SyncTensor[TensorrtTensor]'
# batch_process = 'CpuTensor'
# 'model' = '../onnx/llm.onnx'
# 'model::cache' = '../onnx/llm.trt'

# next = 'sample'

[batchful]
# PluginCacher is used to cache parameters and input data for (tensorrt) plugin
'backend' = 'S[PluginCacher[TensorrtTensor],SyncTensor]'
scheduler = "Batching"

cal_request_size_method = "CalTorchBatchSize" # calc. request_size according to torch tensor size

max = '2047'
'model' = '/workspace/VILA/onnx/decode_batchful.onnx'
'model::cache' = './batchful.trt'
next = 'sample'
# save_dir = "./tmp"

# [batchless_prefill]
[batchless_prefill]
# request_id node_name 
backend = "S[Jump[kvcache],TensorrtTensor,Jump[kvcache],SyncTensor]" # AppendPositionIDsTensor,
instance_num = 4 
max = '1x2047x2560,1x2047x2560,1x2047x2560,1x2047' 
min = '1x1x2560,1x1x2560,1x1x2560,1x1' 
'model' = '/workspace/VILA/onnx/batchless_prefill.onnx' 
'model::cache' = './batchless_prefill.trt' 

[kvcache]
backend = "S[KVCacheTensor,SyncTensor]" 
max_seq_len = 2048 # out_put : reach_max_seq_len
num_layers = 1 # for debug. 32 for llama.  Auto set?

[batchless_decode]
# backend = "RuntimeError"
backend = "S[Jump[kvcache],TensorrtTensor,Jump[kvcache],SyncTensor]" # AppendPositionIDsTensor,
instance_num = 4 
max = '1x1x2560,1x1x2560,1x1x2560,1x1,1x20x2047x128,1x20x2047x128' 
min = '1x1x2560,1x1x2560,1x1x2560,1x1,1x20x1x128,1x20x1x128' 
'model' = '/workspace/VILA/onnx/batchless.onnx' 
'model::cache' = './batchless_decode.trt' 

#TorchPlugin

[sample]
backend = 'S[SampleTensor,Streaming,SyncTensor]'
eos = 2
next = 'check_eos'
temperature = 0.2

[check_eos]
backend = 'S[IsRequestEosFilter,(if)RemoveKVCache, (else)Add[restart:embed_tokens]]'
# map = "result:other,result:data,request_id:request_id"
# next = "embed_tokens"

# IsRequestEosFilter 写入filter, no result
# filter check 'filter', remove it

[embed_tokens]
backend = "S[SyncTensor[EmbedTokensTensor],ADD[restart:batchful,trt_plugin:batchless_decode]]" # ,Jump[batchful]] 
# restart = "batchful" 
# next = "batchful"

tensor = "/workspace/VILA/embed_tokens.pt"
