# Copyright 2021-2023 NetEase.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#  http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# modified from https://github.com/ray-project/ray/blob/505149c151c4fcbaf247312df9f40efde5c60ccb/python/ray/serve/experimental/gradio_visualize_graph.py
# original license: Apache-2.0 license 
# Copyright 2022 The ray Authors.


from typing import Any, Dict, Optional
from collections import defaultdict
import json
import logging
from io import BytesIO
from pydoc import locate


logger = logging.getLogger(__name__)
_gradio = None


def _check_pydot_and_graphviz():
    """Check if pydot and graphviz are installed.
    pydot and graphviz are required for plotting. We check this
    during runtime rather than adding them to Torchpipe dependencies.
    """
    try:
        import pydot
    except ImportError:
        raise ImportError(
            "pydot is required to plot DAG, " "install it with `pip install pydot`."
        )
    try:
        pydot.Dot.create(pydot.Dot())
    except (OSError, pydot.InvocationException):
        raise ImportError("graphviz is required to plot DAG.")


def _fetch_depths(config):
    uuid_to_depths = defaultdict(lambda: 0)
    updated = True
    while updated:
        updated = False
        for key, value in config.items():
            if key == "global && default settings":
                continue
            if not isinstance(value, dict):
                continue
            if "next" in value.keys():
                nexts = value["next"]
                if isinstance(nexts, str):
                    nexts = nexts.split(",")
                    nexts = [x.strip() for x in nexts]
                    value["next"] = nexts
                for i in nexts:
                    if uuid_to_depths[i] < uuid_to_depths[key] + 1:
                        uuid_to_depths[i] = uuid_to_depths[key] + 1
                        updated = True
    return uuid_to_depths


def _dag_to_dot(config, color="#FFA500"):
    # Step 0: check dependencies and init graph
    _check_pydot_and_graphviz()
    import pydot

    graph = pydot.Dot(rankdir="LR", layout="dot", bgcolor="transparent")

    edge_color = "#800080"  # 紫色
    edge_color = "#FFA500"  # 橙色
    edge_color = color

    # 下面这段代码在画图；美化生成的图片：
    graph.set_node_defaults(
        shape="box",
        style="rounded, filled",
        fillcolor="#F0F0F0",
        fontname="Helvetica",
        fontsize="11",
        penwidth="1",
        margin="0.1,0.1",
    )
    graph.set_edge_defaults(
        arrowhead="open",
        arrowsize="0.5",
        color="#707070",
        fontname="Helvetica",
        fontsize="10",
        penwidth="1",
    )
    for key, value in config.items():
        # print(key, value, '\n')
        if key == "global && default settings":
            continue
        if not isinstance(value, dict):
            continue
        node_key = pydot.Node(key, fontcolor=edge_color, color=edge_color)
        graph.add_node(node_key)
    for key, value in config.items():
        if "next" in value.keys():
            nexts = value["next"]
            if isinstance(nexts, str):
                nexts = nexts.split(",")
                nexts = [x.strip() for x in nexts]
                value["next"] = nexts

            for i in nexts:
                node_i = pydot.Node(str(i), fontcolor=edge_color, color=edge_color)
                graph.add_edge(pydot.Edge(key, node_i, color=edge_color))

    return graph


class DAGNode:
    def __init__(self):
        pass


def lazy_import_gradio():
    global _gradio
    if _gradio is None:
        try:
            import gradio
        except ModuleNotFoundError:
            logger.error(
                "Gradio isn't installed. Run `pip install gradio` to use Gradio to "
                "visualize a Serve deployment graph."
            )
            raise

        _gradio = gradio
    return _gradio


def get_block(node, **kwargs):
    gr = lazy_import_gradio()

    result_type = "str"
    node_name = node
    if result_type is None:
        logger.warning(
            f'Return type for "{node_name}" node was not provided. '
            "Defaulting to gr.Textbox."
        )
        return gr.Textbox(**kwargs)

    # Type string output generated by ray.experimental.gradio_utils.type_to_string()
    if result_type == "int":
        return gr.Number(precision=0, **kwargs)
    elif result_type == "float":
        return gr.Number(**kwargs)
    elif result_type == "str":
        show_text = ""

        for key, value in node.items():
            show_text += key + " : " + str(value) + "\n"
        show_text = show_text[: len(show_text) - 1]
        lines = show_text.count("\n")

        return gr.Textbox(
            show_text, **kwargs, interactive=False, lines=lines + 1, visible=True
        )
    elif result_type == "bool":
        return gr.Checkbox(**kwargs)
    elif result_type == "pandas.core.frame.DataFrame":
        return gr.Dataframe(**kwargs)
    elif (
        result_type == "list"
        or result_type == "dict"
        or result_type == "typing.List"
        or result_type == "typing.Dict"
        or result_type == "numpy.ndarray"
    ):
        return gr.JSON(**kwargs)
    elif result_type == "torch.tensor":
        return gr.Image(**kwargs)
    else:
        # Lazy import of PIL. Since PIL is a dependency of Gradio, PIL should be
        # installed if Gradio was successfully imported.
        from PIL import ImageFile

        if issubclass(locate(result_type), ImageFile.ImageFile):
            return gr.Image(**kwargs)

    logger.warning(
        f"Return type for {node_name} node is not valid. Defaulting to gr.Textbox."
    )
    return gr.Textbox(**kwargs)


def postprocessing(data):
    """Add support for types that are not supported by Gradio.

    Some data types like PyTorch tensors, cannot be processed and displayed through
    Gradio. Thus we extend support to these data types by transforming them into a form
    that Gradio can process and display.
    """

    if type_to_string(type(data)) == "torch.Tensor":
        try:
            import torch
            from torchvision import transforms

            # By default Torch tensors are displayed as images. To display them as JSON,
            # the user can simply convert them to numpy arrays.
            transformer = transforms.ToPILImage()
            return transformer(torch.squeeze(data))
        except ModuleNotFoundError:
            logger.warning(
                "Module `torchvision` isn't installed, unable to process torch tensor."
            )
            return data

    return data


class GraphVisualizer:
    def __init__(self):
        lazy_import_gradio()
        self._reset_state()

    def _reset_state(self):
        """Resets state for each new TorchpipeServeHandle representing a new DAG."""
        self.cache = {}
        self.resolved_nodes = 0
        self.finished_last_inference = True

        # Whether user created InputAttributeNodes when building the graph. It is
        # assumed that input is either given through the single InputNode, or
        # exclusively through InputAttributeNodes.
        self.take_input_through_attribute_nodes = False

        # maps DAGNode to unique instance of a gradio block
        self.node_to_block: Dict[DAGNode, Any] = {}
        # maps input nodes to unique instance of interactive gradio block
        self.input_node_to_block: Dict[int, Any] = {}

    def clear_cache(self):
        self.cache = {}

    def _make_blocks(self, depths: Dict[str, int], config) -> None:
        """Instantiates Gradio blocks for each graph node stored in depths.

        Nodes of depth 0 will be rendered in the top row, depth 1 in the next row,
        and so forth. Note that this will render either the single InputNode, or all
        of the InputAttributeNodes; it will not render a mix of the two.

        Args:
            depths: maps uuids of nodes in the DAG to their depth
        """
        gr = lazy_import_gradio()

        levels = {}
        depths["global && default settings"] = -1

        # print(depths)
        for node in depths:
            levels.setdefault(depths[node], []).append(node)

        def render_level(level):
            for node in levels[level]:
                name = node

                # print(config.keys())
                # if "backend" not in config["name"].keys():
                #     backend = ""
                # else:
                #     backend = config[name]["backend"]

                self.input_node_to_block[node] = get_block(config[name], label=name)

                # self.node_to_block[node] = get_block(
                #     node, label=name, interactive=False
                # )

        for level in sorted(levels.keys()):
            with gr.Row():
                render_level(level)

    def hide_fn(self):
        for key, value in self.input_node_to_block.items():
            value.update(visible=False, interactive=True)
        # self.input_node_to_block = None

    def visualize_with_gradio(
        self,
        handle,
        port: Optional[int] = None,
        _launch: bool = True,
        _block: bool = True,
        _share: bool = False,
        save_name="",
    ):
        """Starts deployment graph's Gradio UI.

        Launches a Gradio UI that allows interactive request dispatch and displays
        the evaluated outputs of each node in a deployment graph in real time.

        Args:
            port: The port on which to start the Gradio app. If None, will default to
                Gradio's default.
            _launch: Whether to launch the Gradio app. Used for unit testing purposes.
            _block: Whether to block the main thread while the Gradio server is running.
                Used for unit testing purposes.
        """
        gr = lazy_import_gradio()

        self._reset_state()

        del_keys = []
        if "global && default settings" not in handle.keys():
            handle["global && default settings"] = {}
        for key, value in handle.items():
            if not isinstance(value, dict):
                handle["global && default settings"][key] = value
                del_keys.append(key)

        for key in del_keys:
            del handle[key]

        self.handle = handle
        # Load the root DAG node from handle

        self.dag = handle

        # Get level for each node in dag
        uuid_to_depths = defaultdict(lambda: 0)

        node_to_depths = _fetch_depths(self.dag)

        description = f"\n\n# Visualization \nvisualize torchpipe's configuration.\n"
        css = ".my-4 {margin-top: 0} .py-6 {padding-top: 2.5rem} #refresh-button {flex: none; margin: 0; padding: 0; min-width: 50px; border: none; box-shadow: none; border-radius: 0} #download-label, #upload-label {min-height: 0}"
        # css_2 = css+".h-\[40vh\] {height: 66.67vh} .gradio-container {max-width: 800px; margin-left: auto; margin-right: auto}"

        if save_name:
            graph = _dag_to_dot(self.dag)
            io_file = BytesIO(graph.create(graph.prog, format="svg"))
            with open(save_name + ".svg", "wb") as f:
                f.write(io_file.getvalue())
            print("DAG saved to {}".format(save_name + ".svg"))
            return
        with gr.Blocks(analytics_enabled=False) as demo:
            from PIL import Image

            gr.Markdown(description)
            im = None
            try:
                graph = _dag_to_dot(self.dag, color="#000000")
                im = gr.Image(
                    interactive=False,
                    show_label=False,
                    label="Torchpipe Serve Deployment Graph",
                    value=Image.open(BytesIO(graph.create(graph.prog, format="png"))),
                )
            except ImportError:
                gr.Markdown(
                    "## Warning: cannot show graph illustration.\n"
                    "Python module `pydot` and package `graphviz` is needed to show "
                    "graph illustration. Install pydot with `pip install pydot` and "
                    "graphviz with either `brew install pydot` or `sudo apt install "
                    "graphviz`."
                )
            with gr.Row():
                mes = f"found {len(self.dag)-1} nodes"
                submit = gr.Button(mes).style()
                trigger = gr.Number(0, visible=False)
            self._make_blocks(node_to_depths, self.dag)

            # clear = gr.Button("Clear").style()
            # textbox = gr.Textbox(label="message",interactive=True,visible=True)
            # textbox=gr.Chatbot()

            # Add event listener that sends the request to the deployment graph
            # submit.click(
            #     fn=self._send_request,
            #     inputs=[trigger] + list(self.input_node_to_block.values()),
            #     outputs=trigger,
            # )
            # # Add event listeners that resolve object refs for each of the nodes
            # for node, block in self.node_to_block.items():
            #     trigger.change(
            #         self._get_result, gr.Variable(node.get_stable_uuid()), block
            #     )

            # Resets all blocks if Clear button is clicked
            all_blocks = [*self.node_to_block.values()] + [
                *self.input_node_to_block.values()
            ]
            values = []
            for key, value in self.input_node_to_block.items():
                values.append(value)
            submit.click(self.hide_fn)
            # clear.click(
            #     lambda: self.clear_cache() or [None] * len(all_blocks), [], all_blocks
            # )

        if _launch:
            return demo.launch(
                show_error=True,
                server_port=port,
                prevent_thread_lock=not _block,
                share=_share,
                show_tips=False,
                quiet=True,
            )
